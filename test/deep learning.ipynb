{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93322 (364.54 KB)\n",
      "Trainable params: 93322 (364.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "750/750 [==============================] - 27s 34ms/step - loss: 0.2080 - accuracy: 0.9351 - val_loss: 0.0705 - val_accuracy: 0.9795\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 25s 33ms/step - loss: 0.0548 - accuracy: 0.9827 - val_loss: 0.0523 - val_accuracy: 0.9838\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 26s 35ms/step - loss: 0.0381 - accuracy: 0.9881 - val_loss: 0.0403 - val_accuracy: 0.9885\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 25s 33ms/step - loss: 0.0307 - accuracy: 0.9901 - val_loss: 0.0419 - val_accuracy: 0.9877\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 24s 32ms/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 0.0364 - val_accuracy: 0.9887\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 26s 34ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.0456 - val_accuracy: 0.9881\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 23s 31ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.0353 - val_accuracy: 0.9896\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 25s 34ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.0407 - val_accuracy: 0.9910\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 24s 31ms/step - loss: 0.0136 - accuracy: 0.9950 - val_loss: 0.0385 - val_accuracy: 0.9905\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 23s 31ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0408 - val_accuracy: 0.9900\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0350 - accuracy: 0.9904\n",
      "Test Accuracy: 99.04%\n",
      "Minimum validation accuracy not achieved.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Define the CNN architecture\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "# Check if the minimum validation accuracy condition is met\n",
    "if min(history.history['val_accuracy']) >= 0.994:\n",
    "    print(\"Minimum validation accuracy condition met.\")\n",
    "else:\n",
    "    print(\"Minimum validation accuracy not achieved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " MNIST dataset and achieve a minimum validation accuracy of 99.40%, you can design a simple convolutional neural network. Below is an example using TensorFlow and Keras with code comments for better understanding:This code defines a CNN with three convolutional layers followed by max-pooling layers and fully connected layers. The model is then compiled and trained on the MNIST dataset. The training history is stored in the history variable, and the test accuracy is evaluated at the end.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)1. Define the Problem:\n",
    "Clearly define the problem you want to solve using DL. Identify the application area, such as image recognition, natural language processing, speech recognition, etc.\n",
    "\n",
    "2. Data Collection:\n",
    "Gather a diverse and representative dataset for your problem. Ensure the dataset is large enough to capture the variability in real-world scenarios. Split the data into training, validation, and test sets.\n",
    "\n",
    "3. Data Preprocessing:\n",
    "Clean and preprocess the data to make it suitable for training. Common preprocessing steps include normalization, resizing, handling missing values, and data augmentation (for image data).\n",
    "\n",
    "4. Model Selection:\n",
    "Choose an appropriate DL architecture based on your problem. Common architectures include Convolutional Neural Networks (CNNs) for image-related tasks, Recurrent Neural Networks (RNNs) for sequence data, and Transformers for natural language processing.\n",
    "\n",
    "5. Model Design:\n",
    "Design the architecture of your DL model. Specify the number and types of layers, activation functions, input/output dimensions, etc. Consider using pre-trained models or transfer learning for improved performance, especially if you have a limited amount of labeled data.\n",
    "\n",
    "6. Model Compilation:\n",
    "Compile the DL model by specifying the optimizer, loss function, and evaluation metrics. Common optimizers include Adam, RMSprop, and SGD. Loss functions vary based on the task (e.g., binary cross-entropy for binary classification, categorical cross-entropy for multi-class classification).\n",
    "\n",
    "7. Model Training:\n",
    "Train the DL model on the training data using the compiled architecture. Adjust hyperparameters, such as learning rate and batch size, to find the optimal training configuration. Monitor the model's performance on the validation set during training.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "model.fit(train_data, train_labels, epochs=epochs, batch_size=batch_size, validation_data=(val_data, val_labels))\n",
    "8. Model Evaluation:\n",
    "Evaluate the trained model on the test set to assess its generalization performance. Analyze metrics like accuracy, precision, recall, and F1-score to understand how well the model is performing.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "test_loss, test_accuracy = model.evaluate(test_data, test_labels)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "9. Model Deployment:\n",
    "Deploy the trained model to the target environment, whether it's a mobile device, web application, or server. Consider using cloud services for scalability. Optimize the model for inference speed and resource efficiency.\n",
    "\n",
    "10. Continuous Monitoring and Improvement:\n",
    "Monitor the model's performance in the real-world application. If the performance degrades or new data patterns emerge, retrain the model with fresh data. Implement regular updates and improvements to ensure the model remains effective.\n",
    "\n",
    "Additional Considerations:\n",
    "Ethics and Bias: Be mindful of potential biases in the data and model predictions. Implement fairness and bias mitigation techniques.\n",
    "\n",
    "Privacy and Security: Ensure compliance with privacy regulations. Protect models against adversarial attacks.\n",
    "\n",
    "Interpretability: Consider the interpretability of the model for users and stakeholders. Some applications may require transparent and explainable models.\n",
    "\n",
    "Scalability: Design the system to scale as data and user demand grow. Consider using distributed computing or cloud services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames.\n",
      "Found 0 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\preprocessing\\image.py:1137: UserWarning: Found 46 invalid image filename(s) in x_col=\"image_name\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\preprocessing\\image.py:1137: UserWarning: Found 46 invalid image filename(s) in x_col=\"image_name\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#2)data prepararion\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the CSV file\n",
    "csv_path = 'E:/test/helmets.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Define image and label directories\n",
    "image_dir = 'E:/test/img'\n",
    "df['image_path'] = df['image_name'].apply(lambda x: os.path.join(image_dir, x))\n",
    "\n",
    "# Create ImageDataGenerator for data augmentation and normalization\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "# Create data generators for training and validation\n",
    "batch_size = 32\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=image_dir,\n",
    "    x_col='image_name',\n",
    "    y_col=None,\n",
    "    subset='training',\n",
    "    batch_size=batch_size,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=None,\n",
    "    target_size=(224, 224)  # Adjust the target size as needed\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=image_dir,\n",
    "    x_col='image_name',\n",
    "    y_col=None,\n",
    "    subset='validation',\n",
    "    batch_size=batch_size,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=None,\n",
    "    target_size=(224, 224)  # Adjust the target size as needed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 111, 111, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 54, 54, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 26, 26, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 86528)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               11075712  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11169089 (42.61 MB)\n",
      "Trainable params: 11169089 (42.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#2)model def\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define a simple CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 48s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Load pre-trained VGG16 model without top layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create your model using the pre-trained base model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // batch_size,\n",
    "    epochs=epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(val_generator)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('helmet_detection_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
