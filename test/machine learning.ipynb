{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Load your dataset (replace 'your_dataset.csv' with the actual file name)\n",
    "data = pd.read_csv('E:/test/instagram_reach.csv')\n",
    "\n",
    "# Check the names of the columns in your dataset\n",
    "print(data.columns)\n",
    "\n",
    "# Perform EDA, data preprocessing, and feature engineering\n",
    "\n",
    "# Split the dataset into features (X) and target variables (y)\n",
    "X = data.drop(['Likes', 'Time since posted'], axis=1)  # Adjust column names\n",
    "y_likes = data['Likes']\n",
    "y_time_since_posted = data['Time since posted']  # Adjust column names\n",
    "\n",
    "# Convert categorical variables to numerical representations (use appropriate methods)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train_likes, y_test_likes, y_train_time, y_test_time = train_test_split(\n",
    "    X, y_likes, y_time_since_posted, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Standardize or normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Choose and train a model for predicting likes\n",
    "model_likes = RandomForestRegressor()\n",
    "model_likes.fit(X_train_scaled, y_train_likes)\n",
    "\n",
    "# Choose and train a model for predicting time since posted\n",
    "model_time_since_posted = RandomForestRegressor()\n",
    "model_time_since_posted.fit(X_train_scaled, y_train_time)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "predictions_likes = model_likes.predict(X_test_scaled)\n",
    "predictions_time_since_posted = model_time_since_posted.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the models\n",
    "mse_likes = mean_squared_error(y_test_likes, predictions_likes)\n",
    "mae_time_since_posted = mean_absolute_error(y_test_time, predictions_time_since_posted)\n",
    "\n",
    "print(f'Mean Squared Error (Likes): {mse_likes}')\n",
    "print(f'Mean Absolute Error (Time Since Posted): {mae_time_since_posted}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2implementing Machine Learning (ML) in a real-world application involves several key steps. Below is a high-level overview of the process:\n",
    "\n",
    "Define the Problem:\n",
    "\n",
    "Clearly understand the problem you want to solve or the goal you want to achieve with ML.\n",
    "Define the objectives and success criteria.\n",
    "Collect and Prepare Data:\n",
    "\n",
    "Gather relevant data for your problem. The quality and quantity of data play a crucial role in the success of your model.\n",
    "Clean the data by handling missing values, outliers, and inconsistencies.\n",
    "Split the data into training and testing sets.\n",
    "Choose a Model:\n",
    "\n",
    "Select a suitable ML algorithm based on the nature of the problem (classification, regression, clustering, etc.).\n",
    "Consider factors like model complexity, interpretability, and scalability.\n",
    "Feature Engineering:\n",
    "\n",
    "Extract relevant features from the data.\n",
    "Transform or create new features to enhance the model's performance.\n",
    "Train the Model:\n",
    "\n",
    "Use the training data to train your chosen model.\n",
    "Adjust hyperparameters to optimize model performance.\n",
    "Evaluate the model's performance on the validation set to prevent overfitting.\n",
    "Evaluate and Tune:\n",
    "\n",
    "Assess the model's performance using metrics relevant to your problem (accuracy, precision, recall, etc.).\n",
    "Fine-tune the model by adjusting parameters or trying different algorithms.\n",
    "Deploy the Model:\n",
    "\n",
    "Once satisfied with the model's performance, deploy it to a production environment.\n",
    "Implement necessary infrastructure for serving predictions (APIs, cloud services, etc.).\n",
    "Monitor and Maintain:\n",
    "\n",
    "Continuously monitor the model's performance in the production environment.\n",
    "Implement strategies to handle concept drift and data changes.\n",
    "Regularly update the model as needed, considering new data or changing requirements.\n",
    "Ethical Considerations:\n",
    "\n",
    "Be aware of potential biases in the data and model predictions.\n",
    "Implement fairness and transparency measures.\n",
    "Address privacy concerns and comply with regulations.\n",
    "Scale and Optimize:\n",
    "\n",
    "Optimize the model and infrastructure for scalability.\n",
    "Consider parallelization, distributed computing, or deploying on cloud services.\n",
    "User Feedback and Iteration:\n",
    "\n",
    "Gather feedback from end-users and stakeholders.\n",
    "Iterate on the model and the application based on feedback and changing requirements.\n",
    "Documentation:\n",
    "\n",
    "Document the entire process, including data sources, preprocessing steps, model architecture, and deployment details.\n",
    "Ensure the documentation is comprehensive for future maintenance or model updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2)\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = [\n",
    "    [\"Super built-up Area\", \"19-Dec\", \"Electronic City Phase II\", \"2 BHK\", \"Coomee\", 1056, 2, 1, 39.07],\n",
    "    # ... (add the rest of the data)\n",
    "]\n",
    "\n",
    "columns = [\"rea_type\", \"availability\", \"location\", \"size\", \"society\", \"total_sqft\", \"bath\", \"balcony\", \"price\"]\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(df.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Explore the distribution of numerical features\n",
    "print(df.describe())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Feature Engineering\n",
    "Feature engineering involves transforming and creating new features to improve model performance. In this case, you may want to encode categorical variables like rea_type, availability, location, size, and society. You can also handle missing values and scale numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to numerical using one-hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=[\"rea_type\", \"availability\", \"location\", \"size\", \"society\"], drop_first=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Train an SVM Regressor\n",
    "Now, you can train an SVM regressor using the processed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = df_encoded.drop(\"price\", axis=1)\n",
    "y = df_encoded[\"price\"]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the SVM regressor\n",
    "svr = SVR()\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
